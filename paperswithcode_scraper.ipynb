{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAbVd9O0VWPR721YC40Lnx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulrahmanrihan/paperswithcode_scraper/blob/main/paperswithcode_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YrFi_6MKf0Qr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_abstracts = []\n",
        "def scrape_papers_with_code(search_queries):\n",
        "    base_url = 'https://paperswithcode.com'\n",
        "    search_endpoint = '/search?q='\n",
        "\n",
        "    for query in search_queries:\n",
        "        search_url = base_url + search_endpoint + query.replace(' ', '+')\n",
        "        response = requests.get(search_url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        all_links = []\n",
        "        wanted_links = []\n",
        "        papers = soup.find_all('div', class_=\"paper-card\")\n",
        "        for paper in papers:\n",
        "          links = paper.find_all('a')\n",
        "          for link in links:\n",
        "            if link.get('href') not in all_links:\n",
        "              all_links.append(link.get('href'))\n",
        "\n",
        "        for link in all_links:\n",
        "          research = requests.get(base_url + link)\n",
        "          soup_research = BeautifulSoup(research.text, 'html.parser')\n",
        "          abstract = soup_research.find('div', class_=\"paper-abstract\")\n",
        "          if abstract is not None and abstract.find('p') is not None:\n",
        "            text_abstract = abstract.find('p').text\n",
        "            if text_abstract not in all_abstracts:\n",
        "              all_abstracts.append(text_abstract)"
      ],
      "metadata": {
        "id": "IN4aCJNtf5qV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predefined search queries\n",
        "search_queries = ['machine learning', 'natural language processing', 'computer vision']\n",
        "\n",
        "# Call the function\n",
        "scrape_papers_with_code(search_queries)"
      ],
      "metadata": {
        "id": "jR-ANDAMf6W2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for abstract in list(set(all_abstracts)):\n",
        "  print(abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieHX3-abgsE_",
        "outputId": "b9700e59-6e22-46a0-ea72-b438c1206537"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            TensorFlow Eager is a multi-stage, Python-embedded domain-specific language\n",
            "for hardware-accelerated machine learning, suitable for both interactive\n",
            "research and production. TensorFlow, which TensorFlow Eager extends, requires\n",
            "users to represent computations as dataflow graphs; this permits compiler\n",
            "optimizations and simplifies deployment but hinders rapid prototyping and\n",
            "run-time dynamism. TensorFlow Eager eliminates these usability costs without\n",
            "sacrificing the benefits furnished by graphs: It provides an imperative\n",
            "front-end to TensorFlow that executes operations immediately and a JIT tracer\n",
            "that translates Python functions composed of TensorFlow operations into\n",
            "executable dataflow graphs. TensorFlow Eager thus offers a multi-stage\n",
            "programming model that makes it easy to interpolate between imperative and\n",
            "staged execution in a single package.\n",
            "        \n",
            "\n",
            "            We develop a deep learning based convolutional-regression model that estimates the volumetric soil moisture content in the top ~5 cm of soil. Input predictors include Sentinel-1 (active radar), Sentinel-2 (optical imagery), and SMAP (passive radar) as well as geophysical variables from SoilGrids and modelled soil moisture fields from GLDAS. The model was trained and evaluated on data from ~1300 in-situ sensors globally over the period 2015 - 2021 and obtained an average per-sensor correlation of 0.727 and ubRMSE of 0.054, and can be used to produce a soil moisture map at a nominal 320m resolution. These results are benchmarked against 13 other soil moisture works at different locations, and an ablation study was used to identify important predictors.\n",
            "        \n",
            "\n",
            "            TensorFlow is an interface for expressing machine learning algorithms, and an\n",
            "implementation for executing such algorithms. A computation expressed using\n",
            "TensorFlow can be executed with little or no change on a wide variety of\n",
            "heterogeneous systems, ranging from mobile devices such as phones and tablets\n",
            "up to large-scale distributed systems of hundreds of machines and thousands of\n",
            "computational devices such as GPU cards. The system is flexible and can be used\n",
            "to express a wide variety of algorithms, including training and inference\n",
            "algorithms for deep neural network models, and it has been used for conducting\n",
            "research and for deploying machine learning systems into production across more\n",
            "than a dozen areas of computer science and other fields, including speech\n",
            "recognition, computer vision, robotics, information retrieval, natural language\n",
            "processing, geographic information extraction, and computational drug\n",
            "discovery. This paper describes the TensorFlow interface and an implementation\n",
            "of that interface that we have built at Google. The TensorFlow API and a\n",
            "reference implementation were released as an open-source package under the\n",
            "Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.\n",
            "        \n",
            "\n",
            "            We present a framework for specifying, training, evaluating, and deploying\n",
            "machine learning models. Our focus is on simplifying cutting edge machine\n",
            "learning for practitioners in order to bring such technologies into production.\n",
            "Recognizing the fast evolution of the field of deep learning, we make no\n",
            "attempt to capture the design space of all possible model architectures in a\n",
            "domain- specific language (DSL) or similar configuration language. We allow\n",
            "users to write code to define their models, but provide abstractions that guide\n",
            "develop- ers to write models in ways conducive to productionization. We also\n",
            "provide a unifying Estimator interface, making it possible to write downstream\n",
            "infrastructure (e.g. distributed training, hyperparameter tuning) independent\n",
            "of the model implementation. We balance the competing demands for flexibility\n",
            "and simplicity by offering APIs at different levels of abstraction, making\n",
            "common model architectures available out of the box, while providing a library\n",
            "of utilities designed to speed up experimentation with model architectures. To\n",
            "make out of the box models flexible and usable across a wide range of problems,\n",
            "these canned Estimators are parameterized not only over traditional\n",
            "hyperparameters, but also using feature columns, a declarative specification\n",
            "describing how to interpret input data. We discuss our experience in using this\n",
            "framework in re- search and production environments, and show the impact on\n",
            "code health, maintainability, and development speed.\n",
            "        \n",
            "\n",
            "            This work presents Kornia -- an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. The package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.\n",
            "        \n",
            "\n",
            "            The world is structured in countless ways. It may be prudent to enforce corresponding structural properties to a learning algorithm's solution, such as incorporating prior beliefs, natural constraints, or causal structures. Doing so may translate to faster, more accurate, and more flexible models, which may directly relate to real-world impact. In this dissertation, we consider two different research areas that concern structuring a learning algorithm's solution: when the structure is known and when it has to be discovered.\n",
            "        \n",
            "\n",
            "            Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \\textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \\textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \\url{https://github.com/huggingface/transformers}.\n",
            "        \n",
            "\n",
            "            Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.\n",
            "        \n",
            "\n",
            "            Despite significant progress of deep learning in the field of computer\n",
            "vision, there has not been a software library that covers these methods in a\n",
            "unifying manner. We introduce ChainerCV, a software library that is intended to\n",
            "fill this gap. ChainerCV supports numerous neural network models as well as\n",
            "software components needed to conduct research in computer vision. These\n",
            "implementations emphasize simplicity, flexibility and good software engineering\n",
            "practices. The library is designed to perform on par with the results reported\n",
            "in published papers and its tools can be used as a baseline for future research\n",
            "in computer vision. Our implementation includes sophisticated models like\n",
            "Faster R-CNN and SSD, and covers tasks such as object detection and semantic\n",
            "segmentation.\n",
            "        \n",
            "\n",
            "            This paper describes AllenNLP, a platform for research on deep learning\n",
            "methods in natural language understanding. AllenNLP is designed to support\n",
            "researchers who want to build novel language understanding models quickly and\n",
            "easily. It is built on top of PyTorch, allowing for dynamic computation graphs,\n",
            "and provides (1) a flexible data API that handles intelligent batching and\n",
            "padding, (2) high-level abstractions for common operations in working with\n",
            "text, and (3) a modular and extensible experiment framework that makes doing\n",
            "good science easy. It also includes reference implementations of high quality\n",
            "approaches for both core semantic problems (e.g. semantic role labeling (Palmer\n",
            "et al., 2005)) and language understanding applications (e.g. machine\n",
            "comprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source\n",
            "effort maintained by engineers and researchers at the Allen Institute for\n",
            "Artificial Intelligence.\n",
            "        \n",
            "\n",
            "            In this paper, we illustrate how to fine-tune the entire Retrieval Augment Generation (RAG) architecture in an end-to-end manner. We highlighted the main engineering challenges that needed to be addressed to achieve this objective. We also compare how end-to-end RAG architecture outperforms the original RAG architecture for the task of question answering. We have open-sourced our implementation in the HuggingFace Transformers library.\n",
            "        \n",
            "\n",
            "            Scikit-learn is a Python module integrating a wide range of state-of-the-art\n",
            "machine learning algorithms for medium-scale supervised and unsupervised\n",
            "problems. This package focuses on bringing machine learning to non-specialists\n",
            "using a general-purpose high-level language. Emphasis is put on ease of use,\n",
            "performance, documentation, and API consistency. It has minimal dependencies\n",
            "and is distributed under the simplified BSD license, encouraging its use in\n",
            "both academic and commercial settings. Source code, binaries, and documentation\n",
            "can be downloaded from http://scikit-learn.org.\n",
            "        \n",
            "\n",
            "            Computer graphics can not only generate synthetic images and ground truth but\n",
            "it also offers the possibility of constructing virtual worlds in which: (i) an\n",
            "agent can perceive, navigate, and take actions guided by AI algorithms, (ii)\n",
            "properties of the worlds can be modified (e.g., material and reflectance),\n",
            "(iii) physical simulations can be performed, and (iv) algorithms can be learnt\n",
            "and evaluated. But creating realistic virtual worlds is not easy. The game\n",
            "industry, however, has spent a lot of effort creating 3D worlds, which a player\n",
            "can interact with. So researchers can build on these resources to create\n",
            "virtual worlds, provided we can access and modify the internal data structures\n",
            "of the games. To enable this we created an open-source plugin UnrealCV\n",
            "(http://unrealcv.github.io) for a popular game engine Unreal Engine 4 (UE4). We\n",
            "show two applications: (i) a proof of concept image dataset, and (ii) linking\n",
            "Caffe with the virtual world to test deep network algorithms.\n",
            "        \n",
            "\n",
            "            Deep neural networks (DNNs) are powerful black-box predictors that have achieved impressive performance on a wide variety of tasks. However, their accuracy comes at the cost of intelligibility: it is usually unclear how they make their decisions. This hinders their applicability to high stakes decision-making domains such as healthcare. We propose Neural Additive Models (NAMs) which combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models. NAMs learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. Our experiments on regression and classification datasets show that NAMs are more accurate than widely used intelligible models such as logistic regression and shallow decision trees. They perform similarly to existing state-of-the-art generalized additive models in accuracy, but are more flexible because they are based on neural nets instead of boosted trees. To demonstrate this, we show how NAMs can be used for multitask learning on synthetic data and on the COMPAS recidivism data due to their composability, and demonstrate that the differentiability of NAMs allows them to train more complex interpretable models for COVID-19.\n",
            "        \n",
            "\n",
            "            We introduce CVNets, a high-performance open-source library for training deep neural networks for visual recognition tasks, including classification, detection, and segmentation. CVNets supports image and video understanding tools, including data loading, data transformations, novel data sampling methods, and implementations of several standard networks with similar or better performance than previous studies. Our source code is available at: \\url{https://github.com/apple/ml-cvnets}.\n",
            "        \n",
            "\n",
            "            Bidirectional Encoder Representations from Transformers (BERT) has shown marvelous improvements across various NLP tasks, and consecutive variants have been proposed to further improve the performance of the pre-trained language models. In this paper, we target on revisiting Chinese pre-trained language models to examine their effectiveness in a non-English language and release the Chinese pre-trained language model series to the community. We also propose a simple but effective model called MacBERT, which improves upon RoBERTa in several ways, especially the masking strategy that adopts MLM as correction (Mac). We carried out extensive experiments on eight Chinese NLP tasks to revisit the existing pre-trained language models as well as the proposed MacBERT. Experimental results show that MacBERT could achieve state-of-the-art performances on many NLP tasks, and we also ablate details with several findings that may help future research. Resources available: https://github.com/ymcui/MacBERT\n",
            "        \n",
            "\n",
            "            Misalignment between model predictions and intended usage can be detrimental for the deployment of computer vision models. The issue is exacerbated when the task involves complex structured outputs, as it becomes harder to design procedures which address this misalignment. In natural language processing, this is often addressed using reinforcement learning techniques that align models with a task reward. We adopt this approach and show its surprising effectiveness across multiple computer vision tasks, such as object detection, panoptic segmentation, colorization and image captioning. We believe this approach has the potential to be widely useful for better aligning models with a diverse range of computer vision tasks.\n",
            "        \n",
            "\n",
            "            TF.Learn is a high-level Python module for distributed machine learning\n",
            "inside TensorFlow. It provides an easy-to-use Scikit-learn style interface to\n",
            "simplify the process of creating, configuring, training, evaluating, and\n",
            "experimenting a machine learning model. TF.Learn integrates a wide range of\n",
            "state-of-art machine learning algorithms built on top of TensorFlow's low level\n",
            "APIs for small to large-scale supervised and unsupervised problems. This module\n",
            "focuses on bringing machine learning to non-specialists using a general-purpose\n",
            "high-level language as well as researchers who want to implement, benchmark,\n",
            "and compare their new methods in a structured environment. Emphasis is put on\n",
            "ease of use, performance, documentation, and API consistency.\n",
            "        \n",
            "\n",
            "            We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza.\n",
            "        \n",
            "\n",
            "            Humans read and write hundreds of billions of messages every day. Further, due to the availability of large datasets, large computing systems, and better neural network models, natural language processing (NLP) technology has made significant strides in understanding, proofreading, and organizing these messages. Thus, there is a significant opportunity to deploy NLP in myriad applications to help web users, social networks, and businesses. In particular, we consider smartphones and other mobile devices as crucial platforms for deploying NLP models at scale. However, today's highly-accurate NLP neural network models such as BERT and RoBERTa are extremely computationally expensive, with BERT-base taking 1.7 seconds to classify a text snippet on a Pixel 3 smartphone. In this work, we observe that methods such as grouped convolutions have yielded significant speedups for computer vision networks, but many of these techniques have not been adopted by NLP neural network designers. We demonstrate how to replace several operations in self-attention layers with grouped convolutions, and we use this technique in a novel network architecture called SqueezeBERT, which runs 4.3x faster than BERT-base on the Pixel 3 while achieving competitive accuracy on the GLUE test set. The SqueezeBERT code will be released.\n",
            "        \n",
            "\n",
            "            We present GluonCV and GluonNLP, the deep learning toolkits for computer vision and natural language processing based on Apache MXNet (incubating). These toolkits provide state-of-the-art pre-trained models, training scripts, and training logs, to facilitate rapid prototyping and promote reproducible research. We also provide modular APIs with flexible building blocks to enable efficient customization. Leveraging the MXNet ecosystem, the deep learning models in GluonCV and GluonNLP can be deployed onto a variety of platforms with different programming languages. The Apache 2.0 license has been adopted by GluonCV and GluonNLP to allow for software distribution, modification, and usage.\n",
            "        \n",
            "\n",
            "            TensorFlow is a machine learning system that operates at large scale and in\n",
            "heterogeneous environments. TensorFlow uses dataflow graphs to represent\n",
            "computation, shared state, and the operations that mutate that state. It maps\n",
            "the nodes of a dataflow graph across many machines in a cluster, and within a\n",
            "machine across multiple computational devices, including multicore CPUs,\n",
            "general-purpose GPUs, and custom designed ASICs known as Tensor Processing\n",
            "Units (TPUs). This architecture gives flexibility to the application developer:\n",
            "whereas in previous \"parameter server\" designs the management of shared state\n",
            "is built into the system, TensorFlow enables developers to experiment with\n",
            "novel optimizations and training algorithms. TensorFlow supports a variety of\n",
            "applications, with particularly strong support for training and inference on\n",
            "deep neural networks. Several Google services use TensorFlow in production, we\n",
            "have released it as an open-source project, and it has become widely used for\n",
            "machine learning research. In this paper, we describe the TensorFlow dataflow\n",
            "model in contrast to existing systems, and demonstrate the compelling\n",
            "performance that TensorFlow achieves for several real-world applications.\n",
            "        \n",
            "\n",
            "            Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.\n",
            "        \n",
            "\n",
            "            Convolutional networks are at the core of most state-of-the-art computer\n",
            "vision solutions for a wide variety of tasks. Since 2014 very deep\n",
            "convolutional networks started to become mainstream, yielding substantial gains\n",
            "in various benchmarks. Although increased model size and computational cost\n",
            "tend to translate to immediate quality gains for most tasks (as long as enough\n",
            "labeled data is provided for training), computational efficiency and low\n",
            "parameter count are still enabling factors for various use cases such as mobile\n",
            "vision and big-data scenarios. Here we explore ways to scale up networks in\n",
            "ways that aim at utilizing the added computation as efficiently as possible by\n",
            "suitably factorized convolutions and aggressive regularization. We benchmark\n",
            "our methods on the ILSVRC 2012 classification challenge validation set\n",
            "demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6%\n",
            "top-5 error for single frame evaluation using a network with a computational\n",
            "cost of 5 billion multiply-adds per inference and with using less than 25\n",
            "million parameters. With an ensemble of 4 models and multi-crop evaluation, we\n",
            "report 3.5% top-5 error on the validation set (3.6% error on the test set) and\n",
            "17.3% top-1 error on the validation set.\n",
            "        \n",
            "\n",
            "            Adversarial examples are malicious inputs designed to fool machine learning\n",
            "models. They often transfer from one model to another, allowing attackers to\n",
            "mount black box attacks without knowledge of the target model's parameters.\n",
            "Adversarial training is the process of explicitly training a model on\n",
            "adversarial examples, in order to make it more robust to attack or to reduce\n",
            "its test error on clean inputs. So far, adversarial training has primarily been\n",
            "applied to small problems. In this research, we apply adversarial training to\n",
            "ImageNet. Our contributions include: (1) recommendations for how to succesfully\n",
            "scale adversarial training to large models and datasets, (2) the observation\n",
            "that adversarial training confers robustness to single-step attack methods, (3)\n",
            "the finding that multi-step attack methods are somewhat less transferable than\n",
            "single-step attack methods, so single-step attacks are the best for mounting\n",
            "black-box attacks, and (4) resolution of a \"label leaking\" effect that causes\n",
            "adversarially trained models to perform better on adversarial examples than on\n",
            "clean examples, because the adversarial example construction process uses the\n",
            "true label and the model can learn to exploit regularities in the construction\n",
            "process.\n",
            "        \n",
            "\n",
            "            Scenic is an open-source JAX library with a focus on Transformer-based models for computer vision research and beyond. The goal of this toolkit is to facilitate rapid experimentation, prototyping, and research of new vision architectures and models. Scenic supports a diverse range of vision tasks (e.g., classification, segmentation, detection)and facilitates working on multi-modal problems, along with GPU/TPU support for multi-host, multi-device large-scale training. Scenic also offers optimized implementations of state-of-the-art research models spanning a wide range of modalities. Scenic has been successfully used for numerous projects and published papers and continues serving as the library of choice for quick prototyping and publication of new research ideas.\n",
            "        \n",
            "\n",
            "            This work presents Kornia, an open source computer vision library built upon a set of differentiable routines and modules that aims to solve generic computer vision problems. The package uses PyTorch as its main backend, not only for efficiency but also to take advantage of the reverse auto-differentiation engine to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be integrated into neural networks to train models to perform a wide range of operations including image transformations,camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations on graphical processing units, generating faster systems. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.\n",
            "        \n",
            "\n",
            "            The scale, variety, and quantity of publicly-available NLP datasets has grown rapidly as researchers propose new tasks, larger models, and novel benchmarks. Datasets is a community library for contemporary NLP designed to support this ecosystem. Datasets aims to standardize end-user interfaces, versioning, and documentation, while providing a lightweight front-end that behaves similarly for small datasets as for internet-scale corpora. The design of the library incorporates a distributed, community-driven approach to adding datasets and documenting usage. After a year of development, the library now includes more than 650 unique datasets, has more than 250 contributors, and has helped support a variety of novel cross-dataset research projects and shared tasks. The library is available at https://github.com/huggingface/datasets.\n",
            "        \n",
            "\n",
            "            Most widely-used pre-trained language models operate on sequences of tokens corresponding to word or subword units. By comparison, token-free models that operate directly on raw text (bytes or characters) have many benefits: they can process text in any language out of the box, they are more robust to noise, and they minimize technical debt by removing complex and error-prone text preprocessing pipelines. Since byte or character sequences are longer than token sequences, past work on token-free models has often introduced new model architectures designed to amortize the cost of operating directly on raw text. In this paper, we show that a standard Transformer architecture can be used with minimal modifications to process byte sequences. We characterize the trade-offs in terms of parameter count, training FLOPs, and inference speed, and show that byte-level models are competitive with their token-level counterparts. We also demonstrate that byte-level models are significantly more robust to noise and perform better on tasks that are sensitive to spelling and pronunciation. As part of our contribution, we release a new set of pre-trained byte-level Transformer models based on the T5 architecture, as well as all code and data used in our experiments.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UveUm6HslOWr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}